{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is an implementation based on the [too-many-cook](https://arxiv.org/pdf/2003.11778.pdf) workshop paper."
      ],
      "metadata": {
        "id": "ziE-RKGgpwxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "# %cd /content/drive/Shareddrives/Duong-LongWarwick/ROM\n",
        "# !python -m atari_py.import_roms .\n",
        "%cd '/content/drive/Shareddrives/Duong-KhoiBKHN/PantheonRL-Environment'\n",
        "!ls"
      ],
      "metadata": {
        "id": "UiF8oMYNZKKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c0235d-ba75-46a4-cda3-cc55627bba82"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/Shareddrives/Duong-KhoiBKHN/PantheonRL-Environment\n",
            "manycook_repo\t\t\tovercooked_ai_py\n",
            "OvercookedAI-Environment.ipynb\tPantheonRL-MockEnvironment.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class manycook_arg:\n",
        "    def __init__(self):\n",
        "        # Environment\n",
        "        self.level = 'open-divider_salad' \n",
        "        self.num_agents = 2 \n",
        "        self.max_num_timesteps = 100\n",
        "        self.max_num_subtasks = 14\n",
        "        self.seed = 1\n",
        "        self.with_image_obs = False\n",
        "        self.beta = 1.3\n",
        "\n",
        "        # Navigation Planner\n",
        "        self.alpha = 0.01\n",
        "        self.tau = 2\n",
        "        self.cap = 75\n",
        "        self.main_cap = 100\n",
        "\n",
        "        # Visualizations \n",
        "        self.play = True\n",
        "        self.record = False\n",
        "        \n",
        "        # Models \n",
        "        self.model1 = None \n",
        "        self.model2 = None \n",
        "        self.model3 = None \n",
        "        self.model4 = None\n",
        "\n"
      ],
      "metadata": {
        "id": "eUoFS6ZnkajO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from environment import OvercookedEnvironment\n",
        "# from gym_cooking.envs import OvercookedEnvironment\n",
        "from manycook_repo.recipe_planner.recipe import *\n",
        "from manycook_repo.utils.world import World\n",
        "from manycook_repo.utils.agent import RealAgent, SimAgent, COLORS\n",
        "from manycook_repo.utils.core import *\n",
        "from manycook_repo.misc.game.gameplay import GamePlay\n",
        "from manycook_repo.misc.metrics.metrics_bag import Bag\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import argparse\n",
        "from collections import namedtuple\n",
        "\n",
        "import gym\n",
        "\n",
        "\n",
        "\n",
        "def fix_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "def initialize_agents(arglist):\n",
        "    real_agents = []\n",
        "\n",
        "    with open('utils/levels/{}.txt'.format(arglist.level), 'r') as f:\n",
        "        phase = 1\n",
        "        recipes = []\n",
        "        for line in f:\n",
        "            line = line.strip('\\n')\n",
        "            if line == '':\n",
        "                phase += 1\n",
        "\n",
        "            # phase 2: read in recipe list\n",
        "            elif phase == 2:\n",
        "                recipes.append(globals()[line]())\n",
        "\n",
        "            # phase 3: read in agent locations (up to num_agents)\n",
        "            elif phase == 3:\n",
        "                if len(real_agents) < arglist.num_agents:\n",
        "                    loc = line.split(' ')\n",
        "                    real_agent = RealAgent(\n",
        "                            arglist=arglist,\n",
        "                            name='agent-'+str(len(real_agents)+1),\n",
        "                            id_color=COLORS[len(real_agents)],\n",
        "                            recipes=recipes)\n",
        "                    real_agents.append(real_agent)\n",
        "\n",
        "    return real_agents\n",
        "\n",
        "arglist = manycook_arg()\n",
        "\"\"\"The main loop for running experiments.\"\"\"\n",
        "print(\"Initializing environment and agents.\")\n",
        "env = gym.envs.make(\"gym_cooking:overcookedEnv-v0\", arglist=arglist)\n",
        "obs = env.reset()\n",
        "# game = GameVisualize(env)\n",
        "real_agents = initialize_agents(arglist=arglist)\n",
        "\n",
        "# Info bag for saving pkl files\n",
        "bag = Bag(arglist=arglist, filename=env.filename)\n",
        "bag.set_recipe(recipe_subtasks=env.all_subtasks)\n",
        "\n",
        "while not env.done():\n",
        "    action_dict = {}\n",
        "\n",
        "    for agent in real_agents:\n",
        "        action = agent.select_action(obs=obs)\n",
        "        action_dict[agent.name] = action\n",
        "\n",
        "    obs, reward, done, info = env.step(action_dict=action_dict)\n",
        "\n",
        "    # Agents\n",
        "    for agent in real_agents:\n",
        "        agent.refresh_subtasks(world=env.world)\n",
        "\n",
        "    # Saving info\n",
        "    bag.add_status(cur_time=info['t'], real_agents=real_agents)\n",
        "\n",
        "\n",
        "# Saving final information before saving pkl file\n",
        "bag.set_collisions(collisions=env.collisions)\n",
        "bag.set_termination(termination_info=env.termination_info,\n",
        "        successful=env.successful)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "B3bHnz1wqOf4",
        "outputId": "66d098dc-ee1f-43cf-cc98-7e512bad9f71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a9d93214232f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from environment import OvercookedEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from gym_cooking.envs import OvercookedEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmanycook_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe_planner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmanycook_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWorld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmanycook_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRealAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOLORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'manycook_repo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}