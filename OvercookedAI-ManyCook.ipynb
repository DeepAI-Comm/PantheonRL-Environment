{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This is an implementation based on the [too-many-cook](https://arxiv.org/pdf/2003.11778.pdf) workshop paper."],"metadata":{"id":"ziE-RKGgpwxa"}},{"cell_type":"code","source":["!pip install pygame\n","# !pip install \"/content/drive/MyDrive/Deep-Learning/MARL_Baselines/Packages/pygame-1.9.6.tar.gz\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoVtSjuPkLnO","executionInfo":{"status":"ok","timestamp":1672905190840,"user_tz":-540,"elapsed":6250,"user":{"displayName":"Duong Minh","userId":"05553484543028094036"}},"outputId":"6c24ac1e-08dc-4fdf-bc50-20aa3ff2759c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pygame\n","  Downloading pygame-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pygame\n","Successfully installed pygame-2.1.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# %cd /content/drive/Shareddrives/Duong-LongWarwick/ROM\n","# !python -m atari_py.import_roms .\n","%cd '/content/drive/Shareddrives/Duong-KhoiBKHN/PantheonRL-Environment'\n","!ls"],"metadata":{"id":"UiF8oMYNZKKD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672905197224,"user_tz":-540,"elapsed":2189,"user":{"displayName":"Duong Minh","userId":"05553484543028094036"}},"outputId":"6a172a49-3615-4449-8217-b6036ccbf864"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Shareddrives/Duong-KhoiBKHN/PantheonRL-Environment\n","KhoiRepo       OvercookedAI-Environment.ipynb  PantheonRL-MockEnvironment.ipynb\n","manycook_repo  overcooked_ai_py\t\t       pygame-1.9.6\n"]}]},{"cell_type":"code","source":["class manycook_arg:\n","    def __init__(self):\n","        # Environment\n","        self.level = 'open-divider_salad' \n","        self.num_agents = 2 \n","        self.max_num_timesteps = 100\n","        self.max_num_subtasks = 14\n","        self.seed = 1\n","        self.with_image_obs = False\n","        self.beta = 1.3\n","\n","        # Navigation Planner\n","        self.alpha = 0.01\n","        self.tau = 2\n","        self.cap = 75\n","        self.main_cap = 100\n","\n","        # Visualizations \n","        self.play = True\n","        self.record = False\n","        \n","        # Models \n","        self.model1 = None \n","        self.model2 = None \n","        self.model3 = None \n","        self.model4 = None\n","\n"],"metadata":{"id":"eUoFS6ZnkajO","executionInfo":{"status":"ok","timestamp":1672905197549,"user_tz":-540,"elapsed":6,"user":{"displayName":"Duong Minh","userId":"05553484543028094036"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import sys\n","print(sys.path)\n","sys.path.append('/content/drive/MyDrive/Deep-Learning/MARL_Baselines/PantheonRL-Environment/gym_cooking')\n","sys.path.append('/content/drive/MyDrive/Deep-Learning/MARL_Baselines/PantheonRL-Environment/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RldEPYpag3zl","executionInfo":{"status":"ok","timestamp":1672905471982,"user_tz":-540,"elapsed":280,"user":{"displayName":"Duong Minh","userId":"05553484543028094036"}},"outputId":"b275ae56-7495-49d6-e648-949a3a59c60e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["['/content', '/env/python', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.8/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/Deep-Learning/MARL_Baselines/PantheonRL-Environment', '/content/drive/MyDrive/Deep-Learning/MARL_Baselines/PantheonRL-Environment/manycook_repo']\n"]}]},{"cell_type":"code","source":["# from environment import OvercookedEnvironment\n","# from gym_cooking.envs import OvercookedEnvironment\n","from recipe_planner.recipe import *\n","from utils.world import World\n","from utils.agent import RealAgent, SimAgent, COLORS\n","from utils.core import *\n","from misc.game.gameplay import GamePlay\n","from misc.metrics.metrics_bag import Bag\n","\n","import numpy as np\n","import random\n","import argparse\n","from collections import namedtuple\n","\n","import gym\n","\n","\n","\n","def fix_seed(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","def initialize_agents(arglist):\n","    real_agents = []\n","\n","    with open('utils/levels/{}.txt'.format(arglist.level), 'r') as f:\n","        phase = 1\n","        recipes = []\n","        for line in f:\n","            line = line.strip('\\n')\n","            if line == '':\n","                phase += 1\n","\n","            # phase 2: read in recipe list\n","            elif phase == 2:\n","                recipes.append(globals()[line]())\n","\n","            # phase 3: read in agent locations (up to num_agents)\n","            elif phase == 3:\n","                if len(real_agents) < arglist.num_agents:\n","                    loc = line.split(' ')\n","                    real_agent = RealAgent(\n","                            arglist=arglist,\n","                            name='agent-'+str(len(real_agents)+1),\n","                            id_color=COLORS[len(real_agents)],\n","                            recipes=recipes)\n","                    real_agents.append(real_agent)\n","\n","    return real_agents\n","\n","arglist = manycook_arg()\n","\"\"\"The main loop for running experiments.\"\"\"\n","print(\"Initializing environment and agents.\")\n","env = gym.envs.make(\"gym_cooking:overcookedEnv-v0\", arglist=arglist)\n","obs = env.reset()\n","# game = GameVisualize(env)\n","real_agents = initialize_agents(arglist=arglist)\n","\n","# Info bag for saving pkl files\n","bag = Bag(arglist=arglist, filename=env.filename)\n","bag.set_recipe(recipe_subtasks=env.all_subtasks)\n","\n","while not env.done():\n","    action_dict = {}\n","\n","    for agent in real_agents:\n","        action = agent.select_action(obs=obs)\n","        action_dict[agent.name] = action\n","\n","    obs, reward, done, info = env.step(action_dict=action_dict)\n","\n","    # Agents\n","    for agent in real_agents:\n","        agent.refresh_subtasks(world=env.world)\n","\n","    # Saving info\n","    bag.add_status(cur_time=info['t'], real_agents=real_agents)\n","\n","\n","# Saving final information before saving pkl file\n","bag.set_collisions(collisions=env.collisions)\n","bag.set_termination(termination_info=env.termination_info,\n","        successful=env.successful)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"id":"B3bHnz1wqOf4","executionInfo":{"status":"error","timestamp":1672905474880,"user_tz":-540,"elapsed":963,"user":{"displayName":"Duong Minh","userId":"05553484543028094036"}},"outputId":"4e892e3a-46f3-4dc2-ebb6-6e3051dd250f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing environment and agents.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/gym/envs/registration.py:542: UserWarning: \u001b[33mWARN: Overriding environment overcookedEnv-v0\u001b[0m\n","  logger.warn(f\"Overriding environment {spec.id}\")\n"]},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-fe2742dc4ce0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\"\"\"The main loop for running experiments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing environment and agents.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gym_cooking:overcookedEnv-v0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marglist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marglist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# game = GameVisualize(env)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mdisable_env_checker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mspec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_env_checker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     ):\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPassiveEnvChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepAPICompatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_step_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gym/wrappers/env_checker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_step_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         assert hasattr(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"action_space\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         ), \"The environment must specify an action space. https://www.gymlibrary.ml/content/environment_creation/\"\n","\u001b[0;31mAssertionError\u001b[0m: The environment must specify an action space. https://www.gymlibrary.ml/content/environment_creation/"]}]}]}